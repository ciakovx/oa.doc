\documentclass{article}
\usepackage{apacite}




\usepackage{pgfplotstable} % Puts CSV tables in document
\usepackage{booktabs} % Nicer layout for tables

\usepackage{soul} % For highliting


\usepackage{caption}
\DeclareCaptionFont{black}{ \color{black} }
\DeclareCaptionFormat{listing}{
  \centering
  \colorbox[cmyk]{0.43, 0.35, 0.35,0.01 }{
    \parbox{0.8\textwidth}{\hspace{15pt}#1#2#3}
  }
}
\captionsetup[lstlisting]{ format=listing, labelfont=black, textfont=black, singlelinecheck=false, margin=0pt, font={footnotesize} 
}

\usepackage{color} % Layout of R code
\definecolor{dkgreen}{rgb}{0,0.6,0} %colors for R
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.95}

\usepackage{listings} % For R code
\lstset{frame=tb,
  language=R,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=false,
  tabsize=3,
  frame=lines,
  captionpos=t,
  backgroundcolor=\color{light-gray}
}

\usepackage{float} % Helps with figures & tables
% Alter some LaTeX defaults for better treatment of figures:
% From http://mintaka.sdsu.edu/GF/bibliog/latex/floats.html
    % See p.105 of "TeX Unbound" for suggested values.
    % See pp. 199-200 of Lamport's "LaTeX" book for details.
    %   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.8}	% max fraction of floats at bottom
    %   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\floatpagefraction}{0.7}	% require fuller float pages
	% N.B.: floatpagefraction MUST be less than topfraction !!
    \renewcommand{\dblfloatpagefraction}{0.7}	% require fuller float pages










\begin{document}


\bibliographystyle{apacite}

\title{\bf Open Access Journal Publishing at UT Arlington: \\ \large An Analysis Using Academic Analytics Data in Combination with DOAJ Data}
\author{Clarke Iakovakis}
\maketitle


\section{Objective}
To determine the scale of publishing in open access journals by UT Arlington academic departments, and the open access journals in which they publish.

\section{Introduction}
The scale of open access publishing in both green and gold forms has been steadily increasing. 
As more open access journals become sustainable and reputable, the scale in which researchers want to publish there increases. 
Furthermore, institutional open access policies, such as those passed by faculties at Harvard, MIT, Oregon State University, and most recently, the University of California System, will set a standard for university-supported publishing that many smaller institutions will want to copy.

Testimonies by those individuals at institutions which passed OA policies indicate the importance of building momentum and education behind the movement, in order to ensure that faculty voices are leading the call for a change in publication norms, which is critical for success. 
Therefore in the early stages of building the movement, it will be useful to determine which departments are already publishing in open access journals. 
These individuals will not only be familiar with the process of publication--which may vary somewhat from publication in toll-access journals--and perhaps more importantly may understand the virtues of open access publishing, from the increase in citation metrics to the larger practical and ethical benefits of making their research more accessible.


\section{Clean the Data \& Establish Scope}
In order to discover which open access journals faculty are publishing in, one of course needs data on faculty publications. 
If your institution happens to subscribe to Academic Analytics (AA), this is one source for this data. 
Academic Analytics is a subscription database providing metrics on publication counts, citation counts, research funding, and awards to faculty. 
According to their homepage, "The Academic Analytics Database (AAD) includes information on over 270,000 faculty members associated with more than 9,000 Ph.D. programs and 10,000 departments at more than 385 universities in the United States and abroad" \cite{AcadAn}.



\subsection{Academic Analytics Journals in Scopus}
The first need is to establish the coverage of Academic Analytics journals.
Obviously, if Academic Analytics indexes a limited scope of journals, the data they collect on faculty publications will be of limited utility.
As Scopus is a well-regarded indexing service, the extent to which the set of AA journals is accounted for in Scopus will be telling.

Scopus is %description of Scopus
Scopus provides an updated title list (%insert citation to http://www.elsevier.com/online-tools/scopus/content-overview), which as of February 2014 included 34,119 observations in its initial download. 
For this particular research question, the only variables of interest are the Title variable, i.e. the title of the publication, and the Type variable, classifying the item type.
All datasets used in this study require some cleaning before they can be analyzed, and will have the following transformations applied:
\begin{itemize}
	\item Convert character strings to uppercase
	\item Delete leading/trailing whitespace
	\item Delete duplicate entries
\end{itemize}
The first two points are especially important because the journal lists will be matched based on the precise character string representing the journal title, and any variations in capitalization or spacing will lead to false negatives.
\begin{figure}[ht]
	\centering
	\caption{Clean Scopus data}
	\footnotesize{
		Create a dataframe \textbf{scopus.titles} including only the Title and Type variables.
		For each variable, remove whitespace using the \textit{stringr} package, and call \textit{toupper} to convert to uppercase.
		Use \textit{duplicated} to create a logical vector \textbf{dupe} (YES/NO) of duplicated entries, and subset the \textbf{scopus.titles} dataframe using this vector to return the full set of titles.
			}
	\begin{lstlisting}
	clean.scopus <- function(scopusdata) {
	  # Get a list of all journals indexed by Scopus. 
	  # 
	  # Arg: The raw Scopus journal data
	  # 
	  # Returns: A dataframe of Scopus journals and types, capitalized and with duplicates eliminated
	  
	  scopus.titles <- data.frame("Title"=str_trim(factor(toupper(scopusdata$Title)), side = "both"), "Type"=str_trim(factor(toupper(scopusdata$Type)), side = "both")) # get list of Scopus titles
	  dupe <- duplicated(scopus.titles$Title) # logical vector of duplicates
	  scopus.list <- scopus.titles[!dupe,] # Get all values that are not duplicated
	  scopus.list$Title <- as.character(scopus.list$Title) # Convert Title from factor to character
	  return(scopus.list)
	}
	scopus.list <- clean.scopus(scopus)
\end{lstlisting}
\end{figure}

Cleaning the Scopus data (Figure 1) reveals 156 duplicates, leaving 34,119 unique titles. 
This can then be tabulated (Figure 2) to give us a count of item types in the Scopus data (Table 1).
\begin{figure}[htp]
	\centering
	\caption{Tabulate Scopus types}
	\footnotesize{
		Create a dataframe \textbf{scopus.type.table} of the counts of each type of publication and rename the variable headings.
			}\begin{lstlisting}
	scopus.type.table <- as.data.frame(table(scopus.list$Type)) # Get the Freq for Type
	names(scopus.type.table) <- c("Type", "Count")
	\end{lstlisting}	
\end{figure}

The vast majority (93\%) of these titles are journals; the distribution of types of titles is in Table 1:
\begin{table}[htpb]
	\centering
		\pgfplotstabletypeset[ %I still want to figure out how to use commas here (1000 sep + {,}
		col sep=comma,
		columns/Type/.style={string type},
		columns/Count/.style={string type},
		every head row/.style={
			before row=\toprule,
			after row=\midrule
		},
		every last row/.style={after row=\bottomrule}
	]{scopus.type.table.csv}
	\caption{Content in Scopus}
\end{table}

Academic Analytics subscribers can download a full list of publications that the organization indexes. 
Unfortunately, their data is proprietary; therefore this information is solely for use by University of Texas at Arlington employeess. 

The data comes in CSV format, with 218,469 observations of two variables: journal title and subject discipline.
The primary key in this table is the combination of title and discipline; many journals are classified in more than one discipline, therefore the data must be cleaned to remove duplicate entries. 
It then must be converted to uppercase to make intersection matching more accurate.
This is done with the same basic commands as in the cleaning function already described  (Figure 3).
\begin{figure}[htp]
	\centering
	\caption{Clean Academic Analytics Titles}
	\footnotesize{
		Clean the AA data and return character vector \textbf{aa.journals} consisting of journal titles in Academic Analytics. 
			}
	\begin{lstlisting}
	clean.aa <- function(aadata) {
	  # Get a list of all journals indexed by Academic Analytics. 
	  # 
	  # Arg: The raw Academic Analytics journal data
	  # 
	  # Returns: A character vector of 14,586 Academic Analytics data, capitalized and with duplicates eliminated
	  
	  aa.titles <- data.frame("Title"=str_trim(factor(toupper(aadata$AAD.2011.Journal.List)))) # get list of AA titles
	  dupe <- duplicated(aa.titles) # logical vector of duplicates
	  aa.list <- aa.titles[!dupe,] # return all AA journals as characters, in caps, without duplicates (14,586)
	  aa.list <- as.character(aa.list) # convert from factor to character string
	  return(aa.list)
	}
	aa.list <- clean.aa(aa.journals)
	\end{lstlisting}
\end{figure}

This returns a total of 14,586 unique titles.
Of those, how many are accounted for in 34,119 Scopus entries?
Academic Analytics only provides data on academic journals, so it will likely only match entries from the set of 31,719 journals indexed by Scopus, and not book series, conference proceedings, and trade journals.
Nonetheless, the simple intersect function will scan the full scopus list.
\begin{lstlisting}
	aa.scopus <- intersect(scopus.list$Title, aa.list))\footnote{Why is there a need to specify the variable (Title) for the scopus data, but not the AA data? Because scopus.list is a dataframe of two variables: Title and Type, whereas aa.list is a character vector}
\end{lstlisting}

10,809 publications appear in both Academic Analytics and Scopus. 
Therefore, Academic Analytics account for at maximum approximately one third of journals indexed by Scopus (34.1\% if only Scopus "Journals" are included in the denominator, and 33.3\% if "Trade Journals" are included in addition to "Journals").
AA journal selection criteria is not available, therefore in-depth comment or observation is not possible; suffice it to say that if Academic Analytics indexed a larger proportion of journals, there is a higher probability that their citation data would be enhanced.
Because there is no substantive dataset accounting for UT Arlington publications other than Academic Analytics, it is also impossible to make substantive commentary as to how well AA data covers UT Arlington publications from a comparative perspective.

\subsection{Directory of Open Access Journals in Academic Analytics}
The Directory of Open Access Journals provides a list of existing open access journals.
DOAJ is %describe its purpose here
First, to establish how well Directory of Open Access Journals are covered in Academic Analytics, an intersection can be run in the same fashion as the comparison of AA and Scopus journals. 
The DOAJ data can be freely downloaded on the Web from %cite
The initial dataset includes 9,804 observations and a number of variables, including ISSN, % variables.
The only pertinent variables for this study are the journal name, the alternative journal name, and the publisher.

First, the DOAJ data must be cleaned, using the same functions already described.
This is especially important for the DOAJ data, as a high number of name values include trailing whitespace. 
Two lists must be created: one for the main title, and another for the alternative title, in case Academic Analytics uses that title in its index (this is, indeed, true for one journal in the current study.)
The publisher is also included.
This can be used in later analysis to conduct analysis on publishers indexed by DOAJ, and also to determine publisher overlap between DOAJ and AA lists.
\begin{figure}[htpb]
	\centering
	\caption{Clean the DOAJ Main Titles}
	\footnotesize{
		Clean the DOAJ data and return dataframe \textbf{doaj.list} consisting of the character vector "Title" and the factor vector "Publisher."
			}
	\begin{lstlisting}
	clean.doaj.main <- function(doajdata) {
	  # Get a list of all DOAJ journals and their publishers with whitespace trimmed
	  #
	  # Arg: The raw DOAJ journal data
	  #
	  # Returns: A dataframe of DOAJ journals, capitalized, and their publishers, capitalized, with duplicates eliminated
	  
	  doaj.titles <- data.frame("Title"=str_trim(factor(toupper(doajdata$Title)), side = "both"), "Publisher"=str_trim(factor(toupper(doajdata$Publisher)), side = "both")) # get list of DOAJ titles
	  dupe <- duplicated(doaj.titles) # logical vector of duplicates
	  doaj.list <- doaj.titles[!dupe,] # return all DOAJ titles as characters, in caps, without duplicates (9,786)
	  doaj.list$Title <- as.character(doaj.list$Title) # Convert Title variable to character from factor
	  return(doaj.list)
	}
	doaj.list.trim <- clean.doaj.main(doaj)
	\end{lstlisting}
	
\end{figure}

\begin{figure}[hb]
	\centering
	\caption{Clean the DOAJ Main Titles}
	\begin{lstlisting}
	clean.doaj.alt <- function(doajdata) {
	  # Get a list of all alternative DOAJ journal names and their publishers with spaces deleted.
	  # Because the list is so small, we can safely delete all spaces and any ramifications in visualization are easily fixed
	  #
	  # Arg: The raw DOAJ journal data
	  #
	  # Returns: A dataframe of alternative DOAJ journal titles, capitalized & trimmed, and their publishers, capitalized & trimmed, with duplicates eliminated
	  
	  doaj.alt.titles <- doaj[complete.cases(doajdata$Title.Alternative),] #There are over 2,000 here, but running an intersect with AA only finds 30. Unfortunately, none of these are in this analysis.
	  doaj.alt.titles <- data.frame("Title"=str_replace_all(factor(toupper(doaj.alt.titles$Title.Alternative)), pattern = " ", repl = ""), "Publisher"=str_trim(factor(toupper(doaj.alt.titles$Publisher)), side = "both")) # get list of DOAJ titles
	  dupe <- duplicated(doaj.alt.titles) # logical vector of duplicates
	  doaj.alt.list <- doaj.alt.titles[!dupe,] # return all DOAJ titles as characters, in caps, without duplicates (9,786)
	  doaj.alt.list$Title <- as.character(doaj.alt.list$Title) # Convert Title variable to character from factor
	  return(doaj.alt.list)
	}
	doaj.alt.list.repl <- clean.doaj.alt(doaj)
	\end{lstlisting}
	\footnotesize{
		Clean the DOAJ data and return character vector \textit{doaj.list}.
			}
\end{figure}





After removing 18 duplicates, there are 9,786 unique titles in the DOAJ main title list, and 2,375 unique titles in the alternative title list.

There is a problem with running an intersection between the Academic Analytics data and the DOAJ data at this stage.
For some journals with punctuation in their titles, spacing conventions vary, both within the DOAJ list, and between the DOAJ and AA list.
For instance, on the Academic Analytics list, this journal appears as: {\large \begin{verbatim}Culture Unbound: Journal of Current Cultural Research\end{verbatim}} whereas DOAJ indexes it with an empty space after the main title: {\large \begin{verbatim}Culture Unbound : Journal of Current Cultural Research\end{verbatim}}
While this may seem a small issue, if a faculty member were to have published in this journal, it would not be matched in the analysis, resulting in a false negative.

The problem can be easily solved if we are willing to sacrifice the aesthetic of the titles: \emph{all} spaces can be deleted in both DOAJ and AA  lists (by replacing spaces with nothing and then comparing the titles, Figure 6):
\begin{figure}[htpb]
	\centering
	\caption{Intersection of Trimmed DOAJ \& AA Lists}
	\begin{lstlisting}
	doaj.repl <- str_replace_all(doaj.list, pattern = " ", repl="") # delete ALL spaces on doaj list
	aa.repl <- str_replace_all(aa.list, pattern = " ", repl="") # delete ALL spaces on aa list
	doaj.aa.repl <- intersect(doaj.repl, aa.repl) # 1,226 common journals after deleting all spaces
	\end{lstlisting}
	\footnotesize{
		Create dataframe \textbf{doaj.repl} using \textit{str\_replace\_all} (from the \textit{stringr} package) to delete all spaces in both the AA and the DOAJ journal lists (specifically, replacing spaces with nothing). 
		Return the intersection of the lists to chaqracter vector \textbf{doaj.aa.repl}.
			}
\end{figure}
This identifies 1,226 matching titles, which is the maximum number of journals the two lists have in common for this study, based strictly on character-for-character matching alone.
Based on this figure, Academic Analytics indexes roughly 12.5\% of DOAJ journals.
Just as with the Scopus data, since Academic Analytics selection criteria is not divulged, a complete review of why the number is so low is not possible here.
%insert commentary here about that. Why? What is covered in DOAJ that AA wouldn't cover?

Although deleting all whitespace solves the problem of identifying all common journals, it also returns journal names that look like: {\large \begin{verbatim}CULTUREUNBOUND:JOURNALOFCURRENTCULTURALRESEARCH \end{verbatim}}.
Because journal names will be used to visualize publications for each department, this is not an acceptable solution; however, there is not an easy way to fix the issue and still preserve the integrity of the character string..
Fortunately, the number of journals with this problem is very small, and they can be returned into a separate vector.
By finding the intersection between matching journals on both the AA and the DOAJ lists \emph{without} spaces deleted and matching journals the AA and DOAJ list \emph{with} spaces deleted, the non-matching values will be those journals that \emph{are} on both lists, but that are not discoverable without first deleting spaces:
\begin{figure}[htpb]
	\centering
	\caption{Get List of Journals With Unmatching Punctuation Values On AA \& DOAJ List}
	\begin{lstlisting}
	doaj.aa.punctuation <- function(doajlistdata, aalistdata) {
	  # Delete all spaces in the above created DOAJ & AA Lists, and find the intersection.
	  # Compare that intersection to an intersection of the lists with only leading/trailing whitespace trimmed
	  # Get the journals from the first list only.
	  # 
	  # Args: The above created doaj.list.trim and aa.list
	  #
	  # Returns: A dataframe of journals that appear on both lists, but are not discoverable until all spaces are deleted
	  
	  #Get intersection of DOAJ trimmed list and AA list
	  doaj.aa.trim <- intersect(doajlistdata$Title, aalistdata) # 1,199 common journals after trimming whitespace
	  
	  # Delete all spaces in both lists and get new intersection
	  doaj.repl <- str_replace_all(doajlistdata$Title, pattern = " ", repl="") # delete ALL spaces on doaj list
	  aa.repl <- str_replace_all(aalistdata, pattern = " ", repl="") # delete ALL spaces on aa list
	  doaj.aa.repl <- intersect(doaj.repl, aa.repl) # 1,226 common journals after deleting all spaces
	  
	  # Create a vector of journals that appear in both lists but have punctuation problems aside from leading/trailing whitespace
	  doaj.aa.trim.repl <- str_replace_all(doaj.aa.trim, pattern = " ", repl="") # delete ALL spaces on trimmed list list
	  all.repl <- doaj.aa.repl %in% doaj.aa.trim.repl # get all values in the deleted space list that are in the trimmed space list
	  missing <- doaj.aa.repl[!all.repl] # Number of journals that appear in both lists but have punctuation problems aside from leading/trailing whitespace
	  missing <- as.data.frame(missing) # Convert from string to dataframe so merge will work
	  missing$missing <- as.character(missing$missing) # Coerce the titles to characters
	  names(missing) <- "Title"
	  
	  #Create final dataframe of missing journals and publishers
	  #Need to first create doaj.list with spaces in the Title deleted to merge with the above list
	  doaj.list.repl <- doajlistdata # get the already created list
	  doaj.list.repl$Title <- str_replace_all(doaj.list.repl$Title, pattern = " ", repl="") # trim extra spaces on titles list
	  missing <- merge(x = missing, y = doaj.list.repl, by.y="Title", by.x="Title", all.x = TRUE) # Merge the missing journals with their publishers
	  names(missing) <- c("Title", "Publisher") #Rename columns
	  return(missing)
	}
	missing <- doaj.aa.punctuation(doaj.list.trim, aa.list)
	\end{lstlisting}
	\footnotesize{
		Use function \textit{str\_replace\_all} (from the \textit{stringr} package) to delete all spaces in both the AA and the DOAJ journal lists (specifically, replacing spaces with nothing). 
		Return the intersection of the lists to character vector \textbf{doaj.aa.repl}.

			}

\end{figure}
This vector will then be used in the next step, when the comparison between UT Arlington publications in Academic Analytics is run against the DOAJ list. 

\section{Open Access Publications by UT Arlington Faculty as Reported in Academic Analytics Data}
The next step in the study is to download the publication data on UT Arlington faculty from Academic Analytics in order to determine the scope of open access publisher per department.
Academic Analytics does not provide any information as to whether or not journals are open access. 
AA does collect data on a micro (individual faculty member) level, as inferenced by their provision of "a \textit{numeric} tally of each faculty member’s total scholarly productivity in each of the five areas of scholarly research (journal articles, citations, books, research grants and honorific awards)" (emphasis mine); however, it does not make this micro-level data available. 
Academic Analytics provides publication data aggregated by academic department, through the "Department Articles Market Share" portal, although it does not provide an option to download the total dataset of all publication data for all of the 48 departments at UT Arlington, so each department's data was downloaded as a CSV and saved into the folder "Departments."
The filename was manually keyed and represents the academic department.
The publication name is the primary key of these tables--it is the name of the journal in which researchers for that department have published.
The other variables that will be used in the current analysis are:
\begin{itemize}
	\item \textbf{UnitArticles}: the number of articles published in the specified journal by UT Arlington researchers, aggregated by unit (i.e. department)
	\item \textbf{Publisher}: the publisher of the journal
\end{itemize}
\subsection{Developing the List of Open Access Publications by UT Arlington Faculty}
To ascertain the extent of open access publication, a function will loop through each file, comparing the journal string in the Academic Analytics data to the journal string in the Directory of Open Access Journals data.
\begin{figure}[htpb]
	\centering
	\begin{lstlisting}
	oa.journals <- function(directory) {
	  # Analyze the journal variable in CSV files for each academic department (or school or program), locating matches with journals in the Directory of Open Access Journals
	  #
	  # Arg:
	  #   directory: the file including CSVs for each department (or school or program)
	  #  
	  # Returns:
	  #   a dataframe with three variables: department (or school or program), journal name, and number of articles published in that journal by that department/school/program
	  
	  dirct <- file.path(getwd(), "data", "2014-02-02", directory) # set path to folder with CSV files (by department, school, or program)
	  files <- list.files(dirct) # list files in directory
	  filepath <- file.path(dirct, files) # path of files
	  df <- data.frame(matrix(nrow=0, ncol=3)) # create empty data frame
	  names(df) <- c("Journal", "ArticlesPublished", "Discipline") # name dataframe columns
	  for (i in 1:length(files)) {
	    discipline <- read.csv(file=filepath[i]) # read first csv
	    discbasename <- basename(filepath[i]) # get name of discipline from filename
	    q <- nchar(discbasename) # the next three commands get rid of the ".csv" and return the discipline name. First get an integer value for the number of characters in the basename
	    q <- q-4 # subtract 4 characters from that (".csv")
	    discbasename <- substr(discbasename, 1, q) # get a character variable of the basename minus the ".csv"
	    sbst <- subset(discipline, discipline$UnitArticles >= 1) # create subset of journals with >=1 citation from researchers in the unity
	    Trimmed.Journal.Name <- str_trim(sbst$JournalName, side = "both") # Delete leading and trailing spaces
	    Trimmed.Journal.Name <- toupper(Trimmed.Journal.Name) # Convert journal name to uppercase
	    newdf <- data.frame("JournalName" = Trimmed.Journal.Name, "UnitArticles"=sbst$UnitArticles, stringsAsFactors = FALSE) # create dataframe including only journal name and unit articles and convert to upper case
	    oa <- newdf$Journal \%in\% doaj.list # create logical variable of journals matching DOAJ's list of open access journals as created in the above command
	    # run the first loop with the leading/trailing whitespace removed
	    if (any(oa) == T) { # if there are any matches, 
	      jrns <- subset(newdf, oa) # out of that subset, return the journals that are oa & the unit article count for that journal
	      oadf <- data.frame(jrns$JournalName, jrns$UnitArticles, rep(discbasename,length(jrns$JournalName)), stringsAsFactors = F) # add to the dataframe
	      names(oadf) <- names(df) # change column names so rbind will work
	      df <- rbind(df, oadf)
	    } else { # if there are no T values (i.e. no OA publications)
	      oadf <- data.frame(NA,NA,discbasename) # put NA values into dataframe
	      names(oadf) <- names(df)
	      df <- rbind(df, oadf)
	    }
	    # run a second loop with ALL whitespaces removed
	    Replaced.Journal.Name <- str_replace_all(sbst$JournalName, pattern = " ", repl="") # Delete all spaces in department publication titles
	    Replaced.Journal.Name <- toupper(Replaced.Journal.Name) # Convert journal name to uppercase
	    newdf <- data.frame("JournalName" = Replaced.Journal.Name, "UnitArticles"=sbst$UnitArticles, stringsAsFactors = FALSE) # create dataframe including only journal name and unit articles and convert to upper case
	    oa <- newdf$Journal \%in\% missing # create logical variable of journals matching the department's publications with the journals that have spacing issues
	    if (any(oa) == T) { # if there are any matches, 
	      jrns <- subset(newdf, oa) # out of that subset, return the journals that are oa & the unit article count for that journal
	      oadf <- data.frame(jrns$JournalName, jrns$UnitArticles, rep(discbasename,length(jrns$JournalName)), stringsAsFactors = F) # add to the dataframe
	      names(oadf) <- names(df) # change column names so rbind will work
	      df <- rbind(df, oadf)
	    }
	  }
	  return(df)
	}
	
	depts <- oa.journals("AADepartments")
	
	\end{lstlisting}
	
	\caption{Return a dataframe of all open access publications by UT Arlington faculty}
\end{figure}

\footnotesize{
		Establish a path to the directory of files, create a list of all files in the directory, and establish a path \textbf{filepath} to each individual file.
		Create an empty dataframe \textbf{df} with three columns for "Journal," "ArticlesPublished," and "Discipline."
		Run a loop taking the first file in the directory.
		Because the department name is not included in the table, it must be created using the filename.
		This can be done by reading the entire file basename, counting the characters, and calling \textit{substr} to subtract the final four characters, which are the file extension: .CSV.
		Because the data includes some journals in which the department in question has published zero articles, those are eliminated, leaving us with subset \textbf{sbst}, all cases for which UnitArticles are greater than or equal to one.
		From that subset, whitespace in the journal names is eliminated and they are converted to uppercase, precisely as was done for the DOAJ list to which this list will be compared.
		Then a dataframe \textit{newdf} is created that includes the cleaned journal name and the count of articles published in that journal by the department.
		Next, the journals in that list are compared with the DOAJ list. 
		The operation \%in\%  returns a TRUE/FALSE list, indicating whether the string in one vector is (TRUE) or is not (FALSE) matched to a string in another vector. 
		The resulting vector is returned to \textbf{oa}.
		If there are any matches (i.e., if the department has published in at least one open access journal), as tested with the \textit{any} function, then subset the \textbf{newdf} dataframe by those matches.
		Then create a new dataframe \textbf{oadf} including the journal name, the number of articles that department has published in the journal, and finally repeat the discipline basename for as many values as are returned.
		Change the column names and add the results to the empty dataframe \textbf{df} created at the beginning of the function.
		If there are no matches, insert "NA" values in both the "Journal"  and the "ArticlesPublished" fields.
		
		Above it was established that there are 27 journals that have whitespace variations that cannot be solved with the textit{str\_trim} function, and these were returned to the dataframe textbf{missing}.
		Therefore, go back and remove all whitespace in the journal names for the department, and compare those to the \textbf{missing} vector to retrieve the entire count of open access publications by the department.
		If there are any results, add those to the growing dataframe \textbf{df}. 
		
		Call the function on the folder in which the CSV files are stored, in this case "AADepartments," and return the dataframe to textbf{depts}.
			}
This returns the final dataframe that will be used for analysis, including three variables:
\begin{itemize}
	\item \textbf{Journal}: The name of the open access journal published in by the department.
				      If the department did not find any matches between the department's publications and the DOAJ list, this will be NA.
	\item \textbf{ArticlesPublished}: A count of articles published in that journal by the department during the time period covered by the data.
						If the department did not find any matches between the department's publications and the DOAJ list, this will be NA.
	\item \textbf{Department}: The department name.
\end{itemize}

The departments for which there were no matching values (i.e. no publications in OA journals) can be split from those for which there were matching values:
\begin{figure}
	\centering
	\begin{lstlisting}
	depts.compl <- depts[complete.cases(depts),]
	depts.incompl <- depts[!complete.cases(depts),]	
	\end{lstlisting}
	\footnotesize{
		Subset the textbf{depts} dataframe to exclude any observations with NA values by calling \textit{complete.cases} and return the dataframe to \textbf{depts.compl}.
		Do the same to include observations with NA and return it to \textbf{depts.incompl}
			}
	\caption{Create vector of journals with spacing variations within the character string}
\end{figure}
The primary key is a combination of the Journal and the Department variables, since there are repeating values of both.
The journals for which this analysis found no open access publications:
\begin{table}
	\centering
	\caption{Disciplines With No Open Access Publications}
	\pgfplotstabletypeset[
		col sep=comma,
		columns/Discipline/.style={string type},
		every head row/.style={
			before row=\toprule,
			after row=\midrule
		},
		every last row/.style={after row=\bottomrule}
	]{depts.incompl.csv}
\end{table}
The journals for which there are open access publications will be visualized in the following section.
\subsection{Graphing the List of Open Access Publications by UT Arlington Faculty}
Because there are over 140 observations of open access publications, it is not feasible to view the full data in tabular form.
First it will be helpul to view the publications as aggregated by department.

\begin{figure}
	\centering
	\begin{lstlisting}
	depts.compl$Discipline <- factor(depts.compl$Discipline) # Drop factors
	ArtCounts <- as.data.frame(tapply(depts.compl$ArticlesPublished,depts.compl$Discipline,sum)) #create table of sums of articles applied to the ArticlesPublished column
	names(ArtCounts) <- "ArticlesPublished"
	ArtCounts <- data.frame("Discipline"=as.character(rownames(ArtCounts)), "ArticlesPublished"=as.integer(ArtCounts$ArticlesPublished)) #make the rownames of that df into a variable
	\end{lstlisting}
	\footnotesize{
	Call \textit{factor} on the textbf{dept.compl\$ArticlesPublished} vector to drop unused factor levels from the previous subsetting function.
	Call \textit{tapply} on the ArticlesPublished field, applying the \textit{sum} function and grouping by the factor Discipline, coercing it to a dataframe and renaming the resulting field as "ArticlesPublished."
	\textit{tapply} applies the organizing factor as row names rather than variables in a dataframe, and therefore it's necessary to convert the rownames, coercing them to character, and for good measure coercing the article counts to integers.
			}
	\caption{Tabulate article counts aggregated by discipline}
\end{figure}
\begin{table}
	\centering
	\caption{Article Counts in Open Access Publications by Discipline}
	\pgfplotstabletypeset[
		col sep=comma,
		columns/Discipline/.style={string type},
		columns/Articles Published/.style={string type},
		every head row/.style={
			before row=\toprule,
			after row=\midrule
		},
		every last row/.style={after row=\bottomrule}
	]{artcounts.csv}
\end{table}
It is only a short step to graph this with the ggplot2 package:

\begin{figure}
	\centering
	\begin{lstlisting}
	ArtCounts$Journals.ordered <- reorder(ArtCounts$Discipline, ArtCounts$ArticlesPublished) #sort Discipline by Articles Published
	pth <- pth <- file.path(getwd(), "results", "2014-02-26", "plots") # set a location for plots to be saved
	compl.depts.plot <- ggplot(data=ArtCounts) +
	  geom_bar(aes(x=Journals.ordered,y=ArticlesPublished),fill="orange",color="black",stat="identity") +
	  coord_flip() +
	  geom_text(aes(x=Discipline, y=ArticlesPublished, label=ArticlesPublished), hjust = -0.5, size=6) + #set text labels
	  ggtitle(label="Total Article Counts in Open Access Publications by Department, UTA 2004-2011") +
	  ylab("Number of Articles Published") +
	  xlab("Department") +
	  theme(text = element_text(size=20))
	ggsave("AllDepts.png", path=pth, width=15, height=15) #save files 
	\end{lstlisting}
	\footnotesize{
	Call \textit{reorder} to create a third variable \textbf{Journals.ordered} in the \textbf{ArtCounts} data frame: the disciplines reordered according to article counts; this will be the variable used to sort the data in descending order.
	Establish the path that will be used to save the chart.
	This will be a bar chart with, initially, journals on the x axis and article counts on the y axis, but call \textit{coord\_flip} to create a horizontal bar chart for readability purposes.
	The remaining elements change label text and insert the counts in the chart.
			}
	\caption{Tabulate article counts aggregated by discipline}
\end{figure}
\begin{figure}
	\centering
	\includegraphics{AllDepts.png}
	\label{overflow}
\end{figure}
	






\section{Literature Review}
The UT Arlington Libraries is a strong advocate for open access to scholarly information; that is, "digital, online, free of charge, and free of most copyright and licensing restrictions."  \cite{RefWorks:102}

% \cite{RefWorks:102}









\bibliography{filename}


\appendix
\section{R Code for Open Access Journal Coverage in Academic Analytics}














\end{document}